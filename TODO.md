
TODO:

* Condense slides 8-27 (DONE)
* Use STAR format
* Put Results: on its own page with images
* Include "challenges" and "takeaways/lessons" for each Situation
* Change "History in preparation for now..."
* Change "Backstory"
* Change "Backstory"
* Change "The story so far" to include social/relationships+lessons+results for users
* Condense technical deep dive:
* Remove documentation?
* Condense: What does it look like
* Clean up People First, make easier to read

* Can I think of an example that's data centric, like ETL? Or workflow? CWL?

dev "best practices"
 - continuous:
   * development: jira,git
   * integration: CI + code quality metrics
   * testing: CI + test suite and test metrics
   * delivery: CI + IaC, monitor, validate/acceptance, solutions

bits about "data engineer"
 - hierarchy of needs

next step in my career
 - ML Ops

---
Important discoveries (in order):

https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying
https://hackernoon.com/the-ai-hierarchy-of-needs-18f111fcc007
https://medium.com/@rchang/a-beginners-guide-to-data-engineering-part-i-4227c5c457d7

---

For Bayer... let's improve upon the AWS attempt...
---

Less time, 30 minutes instead of 45. Chop the AWS bits at the end.
The ask:

Purpose: Describe how your experience and skills have prepared you for this
role.

Please focus the presentation and slides on:

* Leading projects either directly or by influence across multiple stakeholders
* Software development, with a focus on best practices
* Data Engineering projects that have enabled business decisions
* How this role fits into your personal career development plan

---
What is the role?

Senior Data Engineer

The primary responsibilities of this role, Senior Data Engineer, are to:

* Work on the deployment, delivery and expansion of data pipelines Collaborate with interdisciplinary scientists to gather requirements for data pipelines;
* Optimize algorithms and data workers to scale horizontally and contribute to the development of new algorithms and capabilities that will enable connected pipeline analytics for all pipelines;
* Work on all aspects of the design, development, validation, scaling and delivery of analytical solutions;
* Work on the development, deployment, and support of systems computing solutions;
* Collaborate with analytics and discovery teams to design and plan data engineering solutions;
* Implement, configure and maintain critical third-party solutions related to engineering work, including compute environments, BI platforms and cloud systems;
* Design and maintain ETL workflows;
* Integrate proactive strategies and best practices to ensure security of stored data;
* Design, build and maintain integrated data solutions such as "data lakes" and "data warehouses";
* Design and maintain data storage systems and access patterns;
* Collaborate and influence with cross-functional stakeholders to develop our strategic target state data infrastructure and organization model;
* Coach and develop others in relevant skills in the data engineering space;
* Partner cross-functionally in the development of shared infrastructure where aligned with Biotechnology business needs;
* Ensure the success of digital strategies within Plant Biotechnology by designing, creating and operating engineered data solutions;
* Partner with teams in data science, reporting, software engineering and operations to accelerate strategies by ensuring the availability and quality of required data systems;
* Have particular focus on bringing value through unique expertise in the creation and optimization of "big data" solutions and the design and execution of distributed computing workflows.

RESTRICTED

Visa Sponsorship is available.

WHO YOU ARE

Your success will be driven by your demonstration of our LIFE values. More specifically related to
this position, Bayer seeks an incumbent who possesses the following:

Required Qualifications:

* Bachelor’s degree in Computational Biology, Bioinformatics, Computer Science or similar discipline with at least seven years of industry experience or Master’s degree in Computational Biology, Bioinformatics, Computer Science or similar discipline with at least five years of industry experience or Doctorate in Computational Biology, Bioinformatics, Computer Science or similar discipline with at least three years of postgraduate experience in data system development or industry experience;
* Technical knowledge with at least five years of experience in SQL and NoSQL databases or other databases (data warehousing, data modeling, etc.);
* Knowledge of algorithms and data structures;
* Experience with tools for authoring workflows, pipelines and databases (Airflow, AWS Step Functions, KubeFlow, RDS, etc.);
* Experience with cloud services (AWS, GCP, Azure);
* Experience with distributed systems;
* Experience with python, Java, R or Scala.

Preferred Qualifications:

* Proven ability to plan, schedule and deliver quality software, DevOps methodology;
* Experience in running production cloud systems and diagnosing and fixing problems;
* Experience developing, communicating, and executing on data strategy in a business setting;
* Experience developing analytics-driven visualizations that integrate data to drive business value;
* Demonstrated ability to deliver solutions that utilize Bayer’s current data ecosystem, including the Velocity framework, the 360 assets, playbooks, ontology and decision capture;
* Experience in management and stewardship of data from external collaborations.

